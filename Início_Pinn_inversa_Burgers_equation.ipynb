{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2ZZlSMTBAkaAQJ8OjKXVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoAlexandreFerreira/PINNs/blob/main/In%C3%ADcio_Pinn_inversa_Burgers_equation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inverse PINNs - Burgers"
      ],
      "metadata": {
        "id": "Tk_bMUheej36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bibliotecas"
      ],
      "metadata": {
        "id": "L0thpNFVe005"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YRDQ4QieilJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras import Sequential\n",
        "from keras.layers import Input, Dense\n",
        "from time import time\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import Ones, GlorotNormal, he_normal, Zeros\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import pandas as pd\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import scipy.optimize\n",
        "keras.backend.set_floatx('float32')\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DescriÃ§Ã£o do Problema\n",
        "\n",
        "CriaÃ§Ã£o de uma rede neural para problema inverso da equaÃ§Ã£o de Burger, conforme:\n",
        "\n",
        "  $\\frac{\\partial u}{\\partial t} + Î»_1u\\frac{\\partial u}{\\partial x} = Î»_2\\frac{\\partial^2 u}{\\partial x^2}$\n",
        "\n",
        "  $ x \\in [-1,1]$\n",
        "\n",
        "  $ t \\in [0,1] $\n",
        "\n",
        "  com os valores reais de $Î»_1 = 1$ e $\\lambda _2 = ğœˆ = \\frac{0.01}{Ï€}$\n",
        "\n",
        "  **Em problemas diretos**, tinha-se: Modelos â†’ Dados (previsÃ£o)\n",
        "\n",
        "  JÃ¡ em **problemas inversos**, tÃªm-se: Dados â†’ Modelo (obter os parÃ¢metros do modelo)"
      ],
      "metadata": {
        "id": "4f2cdOQnfaiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PINNS para problemas inversos -- \"Data-driven Discovery of Nonlinear Partial Differential Equations\"\n",
        "\n",
        "**Problemas Inversos**: Dados â†’ ParÃ¢metros do modelo:\n",
        "\n",
        "Dados â†’ PINN â†’ ParÃ¢metros do modelo, que neste caso sÃ£o os parÃ¢metros da EquaÃ§Ã£o diferencial parcial\n",
        "\n",
        "Em Raissi *et al*, (2017) Ã© dito que a forma geral das equaÃ§Ãµes diferenciais parciais nÃ£o lineares e parametrizadas Ã©:\n",
        "\n",
        "$u_t + ğ•[u;Î»] = 0$\n",
        "\n",
        "com $u_t$ sendo a soluÃ§Ã£o e $ ğ•[u;Î»]$ um operador nÃ£o linear parametrizado por $Î»$.\n",
        "\n",
        "Ou seja, a PINN Ã© utilizada para obter Î».\n",
        "\n",
        "###Pelo teorema da aproximaÃ§Ã£o universal, as redes neurais podem ser utilizadas para aproximar qualquer funÃ§Ã£o. (https://book.sciml.ai/notes/03/)\n",
        "\n",
        "Sendo a rede neural descrita pela equaÃ§Ã£o:\n",
        "\n",
        "$N(X) = W_nÏƒ_{n-1}(W_{n-1}Ïƒ_{n-2}(...(W_2Ïƒ(W_1X + b_1) + b_2) + ...) + b_{n-1}) + b_n$\n",
        "\n",
        "Do teorema podemos assumir entÃ£o que:\n",
        "\n",
        "$N(x,t) â‰ˆ u(x,t)$\n",
        "\n",
        "Logo:\n",
        "\n",
        "$N_t + Î»_1NN_x - Î»_2N_{xx} â‰ˆ u_t + Î»_1uu_x - Î»_2u_{xx} = 0$\n",
        "\n",
        "A funÃ§Ã£o $f$ Ã© portanto:\n",
        "\n",
        "$f(x,t) = N_t + Î»_1NN_x - Î»_2N_{xx} = N_t + Î–[N, Î»] â‰ˆ 0$\n",
        "\n",
        "###Custo - Loss\n",
        "\n",
        "Para a pinn inversa, Ã© definido um certo nÃºmero de pontos dentro do domÃ­nio ($N_u$) o qual Ã© verificado o valor da funÃ§Ã£o $f$ nesses pontos, e em seguida minimizado o erro associado ao valor predito e o real, por meio da equaÃ§Ã£o:\n",
        "\n",
        "$MSE_f = \\frac{1}{N_u}âˆ‘^{N_u}_{i=1}|f(t_u^i, x_u^i)|^2$\n",
        "\n",
        "Por se tratar de um problema inverso, os dados sÃ£o conhecidos, assim, o segundo custo Ã© da forma:\n",
        "\n",
        "$MSE_u = \\frac{1}{N_u}âˆ‘^{N_u}_{i=1}|u(t_u^i, x_u^i) - N(t^i_u, x_u^i)|^2$\n",
        "\n",
        "$MSE_{total} = MSE_f + MSE_u$"
      ],
      "metadata": {
        "id": "E7FmdZbCkzE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ParÃ¢metros"
      ],
      "metadata": {
        "id": "k_iyU3mQfCdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pi = tf.constant(np.pi)\n",
        "mi = 0.01/tf.constant(np.pi)\n",
        "dados = loadmat('burgers_shock.mat')\n",
        "x_dados = dados['x'].flatten()[:,None]\n",
        "t_dados = dados['t'].flatten()[:,None]\n",
        "u_dados = np.real(dados['usol']).T\n",
        "\n",
        "X, T = np.meshgrid(x_dados, t_dados)\n",
        "\n",
        "\n",
        "#Definindo os pontos X\n",
        "N_0 = 100 #100 pontos para condiÃ§Ã£o inicial\n",
        "N_b = 100 #100 pontos para condiÃ§Ã£o de contorno\n",
        "N_r = 10000 #Pontos para a edp\n",
        "\n",
        "#Pontos do domÃ­nio, dado pelo Maziar\n",
        "tmin = 0. ; tmax = 1.\n",
        "xmin = -1.; xmax = 1.\n",
        "X_real = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "U_real = u_dados.flatten('F')[:,None]\n",
        "\n",
        "lb = tf.constant(X_real[0], dtype = 'float32'); ub = tf.constant(X_real[-1], dtype = 'float32')\n",
        "\n",
        "lambda1 = tf.Variable(initial_value = 5., trainable = True)\n",
        "lambda2 = tf.Variable(initial_value = 0.001, trainable = True)"
      ],
      "metadata": {
        "id": "AFVCMCRofEYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inicial(x):\n",
        "  return -tf.sin(pi*x)\n",
        "\n",
        "def contorno(t, x):\n",
        "  n = x.shape[0]\n",
        "  return tf.zeros((n,1))\n",
        "\n",
        "#Obtendo pontos para a condiÃ§Ã£o inicial\n",
        "t0 = tf.zeros((N_0,1))*lb[1].numpy()\n",
        "x0 = tf.random.uniform((N_0,1), lb[1].numpy(), ub[1].numpy()) #Colocando os valores de x0 em ordem aleatoria, indo de -1 a 1\n",
        "x0 = tf.concat([t0, x0], 1) #Criando uma matriz com os valores de tempo = 0 e de x0\n",
        "\n",
        "#Valores de u para a condiÃ§Ã£o inicial\n",
        "u_ini = inicial(x0[:,1:2])\n",
        "\n",
        "#Repetindo o processo, mas para a condiÃ§Ã£o de contorno\n",
        "tb = tf.random.uniform((N_b,1), lb[0].numpy(), ub[0].numpy())\n",
        "xb = lb[1].numpy() + (ub[1].numpy() - lb[1].numpy()) * tf.keras.backend.random_bernoulli((N_b,1), 0.5)\n",
        "xb = tf.concat([tb, xb], 1)\n",
        "\n",
        "#Valores na condiÃ§Ã£o de contorno\n",
        "u_cont = contorno(xb[:,0:1], xb[:,1:2])\n",
        "\n",
        "#Repetindo o processo, mas agora Ã© para obter os pontos da EDP\n",
        "tr = tf.random.uniform((N_r,1), lb[0].numpy(), ub[0].numpy())\n",
        "xr = tf.random.uniform((N_r,1), lb[1].numpy(), ub[1].numpy())\n",
        "xr = tf.concat([tr, xr], 1)\n",
        "\n",
        "#Fazendo uma lista, para uso posterior\n",
        "X_cond = [x0, xb]\n",
        "u_cond = [u_ini, u_cont]"
      ],
      "metadata": {
        "id": "WLEmkN-M8C-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qtd_pontos = len(x_dados)*len(t_dados)\n",
        "id = np.random.choice(qtd_pontos, N_r, replace=False)\n",
        "X_treino = X_real[id]\n",
        "U_treino = U_real[id]"
      ],
      "metadata": {
        "id": "vPwwmjt32xDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dos\", qtd_pontos, \"dados fornecidos serÃ£o usados\", X_treino.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fJHjX0T4mG3",
        "outputId": "72d3c13b-f35a-4d58-8940-32ae3704f4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dos 25600 dados fornecidos serÃ£o usados 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Agora criando o modelo de Rede neural\n",
        "\n",
        "def modelopinn(nos, camadas_ocultas):\n",
        "  modelo = Sequential()\n",
        "  #Inserindo o numero de variaveis de entrada\n",
        "  modelo.add(Input(shape = (2,)))\n",
        "  #Escala de entrada, mapeando os pontos de maximo e minimo\n",
        "  modelo.add(keras.layers.Lambda(\n",
        "      lambda x: 2.0*(x - lb)/(ub - lb) - 1.0\n",
        "  ))\n",
        "  for i in range(camadas_ocultas):\n",
        "        modelo.add(Dense(nos, activation='tanh', kernel_initializer=GlorotNormal())) #camada oculta\n",
        "\n",
        "\n",
        "\n",
        "  modelo.add(Dense(1)) #camada de saÃ­da\n",
        "  lambda1 = modelo.add_weight(name='lambda1', initializer=tf.constant_initializer(5.0), trainable=True)\n",
        "  lambda2 = modelo.add_weight(name='lambda2', initializer=tf.constant_initializer(0.1), trainable=True)\n",
        "  modelo.summary()\n",
        "  return modelo, lambda1, lambda2"
      ],
      "metadata": {
        "id": "pfg_Coq9ifeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modelo, lambda1, lambda2 = modelopinn(20,8)\n",
        "modelo, lambda1, lambda2 = modelopinn(20,8)\n",
        "\n",
        "otimizador = Adam(learning_rate = 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "guWAss-s2JdD",
        "outputId": "d0c65dfd-dcb3-43e1-f6d7-12fe711bf21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lambda (\u001b[38;5;33mLambda\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚              \u001b[38;5;34m60\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  â”‚             \u001b[38;5;34m420\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚              \u001b[38;5;34m21\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,023\u001b[0m (11.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,023</span> (11.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,023\u001b[0m (11.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,023</span> (11.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"O lambda 1 real Ã© 1 e o lambda 2 real Ã©\", 0.01/pi, \"lambda 1 estimado foi: \", lambda1.numpy(), \"lambda 2 estimado foi:\", lambda2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r4yqZVHtPFF",
        "outputId": "ff0daa95-e54b-4d88-9108-de5b2aca56f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O lambda 1 real Ã© 1 e o lambda 2 real Ã© tf.Tensor(0.0031830987, shape=(), dtype=float32) lambda 1 estimado foi:  5.0 lambda 2 estimado foi: 0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"VariÃ¡veis treinÃ¡veis:\", [var.name for var in modelo.trainable_variables])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P70LCnPh2cv_",
        "outputId": "b4cee24e-cb6e-4cd4-bb4e-6b670af9faab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VariÃ¡veis treinÃ¡veis: ['lambda1', 'lambda2', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias', 'kernel', 'bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#E tirando os gradientes, para calcular a edp\n",
        "def gradiente(modelo, X_r):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "\n",
        "    #Registrando tempo e posiÃ§Ã£o para a diferenciaÃ§Ã£o automÃ¡tica\n",
        "    t, x = X_r[:, 0:1], X_r[:,1:2]\n",
        "    tape.watch(t)\n",
        "    tape.watch(x)\n",
        "\n",
        "    #previsÃ£o do modelo\n",
        "    u = modelo(tf.stack([t[:,0], x[:,0]], 1))\n",
        "    #gradiente du/dx\n",
        "    ux = tape.gradient(u, x)\n",
        "\n",
        "\n",
        "  #gradiente du/dt\n",
        "  ut = tape.gradient(u, t)\n",
        "  #gradiente duÂ²/dÂ²x\n",
        "  uxx = tape.gradient(ux, x)\n",
        "\n",
        "  del tape\n",
        "\n",
        "  return ut + lambda1*u*ux - lambda2*uxx\n",
        "\n",
        "def MSE(modelo, xr, X_cond, u_cond):\n",
        "\n",
        "    #Erro edp\n",
        "    r = gradiente(modelo, xr)\n",
        "    erro = tf.reduce_mean(tf.square(r))\n",
        "\n",
        "    loss = erro\n",
        "\n",
        "    #Erro da rede neural\n",
        "    for i in range(len(X_cond)):\n",
        "        u_pred = modelo(X_cond[i])\n",
        "        loss += tf.reduce_mean(tf.square(u_cond[i] - u_pred))\n",
        "\n",
        "    return erro, loss\n",
        "\n",
        "def grad(modelo, xr, X_cond, u_cond):\n",
        "  #tirando o gradiente em relaÃ§Ã£o ao modelos, para que eles sejam atualizados posteriormente\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    #tape.gradient(modelo.trainable_variables)\n",
        "    erro, loss = MSE(modelo, xr, X_cond, u_cond)\n",
        "\n",
        "  g = tape.gradient(loss, modelo.trainable_variables)\n",
        "  del tape\n",
        "\n",
        "  return erro, loss, g"
      ],
      "metadata": {
        "id": "mBKDXjB8s5el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#etapa de treinamento como uma funÃ§Ã£o do TensorFlow para aumentar a velocidade do treinamento\n",
        "@tf.function\n",
        "def train_step(modelo):\n",
        "  #Calculando a perda do modelo em relaÃ§Ã£o ao modelo, com a funÃ§Ã£o grad\n",
        "  erro, loss, grad_theta = grad(modelo, xr, X_cond, u_cond)\n",
        "\n",
        "  #Aplicando o gradiente as variaveis do modelo de rede neural\n",
        "  otimizador.apply_gradients(zip(grad_theta, modelo.trainable_variables))\n",
        "\n",
        "  return erro, loss\n",
        "\n",
        "itr = 5000\n",
        "historico = []\n",
        "erro_aux = []\n",
        "t0 = time()\n",
        "\n",
        "for i in range(itr+1):\n",
        "\n",
        "    erro, loss = train_step(modelo)\n",
        "\n",
        "    #Salvando os erros para listar\n",
        "    historico.append(loss.numpy())\n",
        "    erro_aux.append(erro.numpy)\n",
        "\n",
        "    if i%10 == 0:\n",
        "        print(i,\"Loss treino: {:10.8e}, Loss edp: {:10.8e}, Lambda1: {:1.1e}, Lambda2: {:1.1e}\".format(loss, erro, lambda1.numpy(), lambda2.numpy()))\n",
        "\n",
        "print('\\nTempo de treino da rede neural: {} segundos'.format(time()-t0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SqMvN-C05g4D",
        "outputId": "d1e3d67a-a636-4b8e-b129-d78397676f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Loss treino: 5.08220136e-01, Loss edp: 8.06579366e-03, Lambda1: 5.0e+00, Lambda2: 9.9e-02\n",
            "10 Loss treino: 2.88259327e-01, Loss edp: 1.91083015e-03, Lambda1: 5.0e+00, Lambda2: 9.6e-02\n",
            "20 Loss treino: 2.80728102e-01, Loss edp: 3.79672204e-03, Lambda1: 5.0e+00, Lambda2: 9.7e-02\n",
            "30 Loss treino: 2.61018574e-01, Loss edp: 2.13662256e-03, Lambda1: 5.0e+00, Lambda2: 1.0e-01\n",
            "40 Loss treino: 2.29525119e-01, Loss edp: 4.49439045e-03, Lambda1: 5.0e+00, Lambda2: 1.1e-01\n",
            "50 Loss treino: 1.89789772e-01, Loss edp: 1.28850313e-02, Lambda1: 5.0e+00, Lambda2: 1.1e-01\n",
            "60 Loss treino: 1.65807575e-01, Loss edp: 3.62853259e-02, Lambda1: 5.0e+00, Lambda2: 9.7e-02\n",
            "70 Loss treino: 1.54401794e-01, Loss edp: 4.15884778e-02, Lambda1: 5.0e+00, Lambda2: 8.0e-02\n",
            "80 Loss treino: 1.47056535e-01, Loss edp: 3.17831412e-02, Lambda1: 5.0e+00, Lambda2: 6.9e-02\n",
            "90 Loss treino: 1.40068531e-01, Loss edp: 2.65087001e-02, Lambda1: 5.0e+00, Lambda2: 6.7e-02\n",
            "100 Loss treino: 1.33572474e-01, Loss edp: 2.48591416e-02, Lambda1: 5.0e+00, Lambda2: 5.9e-02\n",
            "110 Loss treino: 1.27218068e-01, Loss edp: 2.35133637e-02, Lambda1: 5.0e+00, Lambda2: 4.8e-02\n",
            "120 Loss treino: 1.22002959e-01, Loss edp: 2.21712366e-02, Lambda1: 5.1e+00, Lambda2: 4.1e-02\n",
            "130 Loss treino: 1.18417263e-01, Loss edp: 2.39726417e-02, Lambda1: 5.1e+00, Lambda2: 3.7e-02\n",
            "140 Loss treino: 1.14974938e-01, Loss edp: 2.19057854e-02, Lambda1: 5.1e+00, Lambda2: 3.4e-02\n",
            "150 Loss treino: 1.11614659e-01, Loss edp: 2.13453211e-02, Lambda1: 5.1e+00, Lambda2: 3.4e-02\n",
            "160 Loss treino: 1.08911693e-01, Loss edp: 2.04213709e-02, Lambda1: 5.1e+00, Lambda2: 3.2e-02\n",
            "170 Loss treino: 1.06264286e-01, Loss edp: 1.89902764e-02, Lambda1: 5.1e+00, Lambda2: 2.9e-02\n",
            "180 Loss treino: 1.03770159e-01, Loss edp: 1.80559605e-02, Lambda1: 5.1e+00, Lambda2: 2.4e-02\n",
            "190 Loss treino: 1.01311721e-01, Loss edp: 1.71794444e-02, Lambda1: 5.2e+00, Lambda2: 1.8e-02\n",
            "200 Loss treino: 9.90412310e-02, Loss edp: 1.58888847e-02, Lambda1: 5.2e+00, Lambda2: 1.1e-02\n",
            "210 Loss treino: 9.64454412e-02, Loss edp: 1.52434083e-02, Lambda1: 5.2e+00, Lambda2: 2.6e-03\n",
            "220 Loss treino: 9.36799943e-02, Loss edp: 1.36408247e-02, Lambda1: 5.2e+00, Lambda2: -6.6e-03\n",
            "230 Loss treino: 9.11054462e-02, Loss edp: 1.27143627e-02, Lambda1: 5.2e+00, Lambda2: -1.6e-02\n",
            "240 Loss treino: 8.86738077e-02, Loss edp: 1.18794590e-02, Lambda1: 5.2e+00, Lambda2: -2.5e-02\n",
            "250 Loss treino: 8.83814991e-02, Loss edp: 1.26594836e-02, Lambda1: 5.2e+00, Lambda2: -3.3e-02\n",
            "260 Loss treino: 8.50290582e-02, Loss edp: 1.14386790e-02, Lambda1: 5.2e+00, Lambda2: -3.8e-02\n",
            "270 Loss treino: 8.27874392e-02, Loss edp: 1.11510297e-02, Lambda1: 5.2e+00, Lambda2: -4.4e-02\n",
            "280 Loss treino: 8.06558356e-02, Loss edp: 1.05910832e-02, Lambda1: 5.2e+00, Lambda2: -5.0e-02\n",
            "290 Loss treino: 7.87736848e-02, Loss edp: 1.03888726e-02, Lambda1: 5.3e+00, Lambda2: -5.6e-02\n",
            "300 Loss treino: 7.79306218e-02, Loss edp: 1.12289013e-02, Lambda1: 5.3e+00, Lambda2: -6.0e-02\n",
            "310 Loss treino: 7.50805885e-02, Loss edp: 8.84282868e-03, Lambda1: 5.3e+00, Lambda2: -6.4e-02\n",
            "320 Loss treino: 7.37559646e-02, Loss edp: 8.41086078e-03, Lambda1: 5.3e+00, Lambda2: -6.8e-02\n",
            "330 Loss treino: 7.21319318e-02, Loss edp: 8.10049195e-03, Lambda1: 5.3e+00, Lambda2: -7.2e-02\n",
            "340 Loss treino: 7.14103952e-02, Loss edp: 7.39259645e-03, Lambda1: 5.3e+00, Lambda2: -7.5e-02\n",
            "350 Loss treino: 6.97203502e-02, Loss edp: 6.41583698e-03, Lambda1: 5.3e+00, Lambda2: -7.9e-02\n",
            "360 Loss treino: 6.89638630e-02, Loss edp: 6.54371269e-03, Lambda1: 5.3e+00, Lambda2: -8.2e-02\n",
            "370 Loss treino: 6.81333244e-02, Loss edp: 5.77931758e-03, Lambda1: 5.3e+00, Lambda2: -8.5e-02\n",
            "380 Loss treino: 6.73665553e-02, Loss edp: 5.77455200e-03, Lambda1: 5.4e+00, Lambda2: -8.8e-02\n",
            "390 Loss treino: 6.78684562e-02, Loss edp: 7.03845080e-03, Lambda1: 5.4e+00, Lambda2: -9.0e-02\n",
            "400 Loss treino: 6.67420775e-02, Loss edp: 6.27476489e-03, Lambda1: 5.4e+00, Lambda2: -9.3e-02\n",
            "410 Loss treino: 6.57971576e-02, Loss edp: 5.55717526e-03, Lambda1: 5.4e+00, Lambda2: -9.7e-02\n",
            "420 Loss treino: 6.50293082e-02, Loss edp: 4.95189149e-03, Lambda1: 5.4e+00, Lambda2: -1.0e-01\n",
            "430 Loss treino: 6.44867718e-02, Loss edp: 4.85885609e-03, Lambda1: 5.4e+00, Lambda2: -1.0e-01\n",
            "440 Loss treino: 6.39007986e-02, Loss edp: 4.77896025e-03, Lambda1: 5.4e+00, Lambda2: -1.1e-01\n",
            "450 Loss treino: 6.33879155e-02, Loss edp: 4.99758590e-03, Lambda1: 5.4e+00, Lambda2: -1.1e-01\n",
            "460 Loss treino: 6.35085553e-02, Loss edp: 5.87886805e-03, Lambda1: 5.4e+00, Lambda2: -1.2e-01\n",
            "470 Loss treino: 6.21631518e-02, Loss edp: 4.76089632e-03, Lambda1: 5.4e+00, Lambda2: -1.2e-01\n",
            "480 Loss treino: 6.15415424e-02, Loss edp: 4.46854532e-03, Lambda1: 5.4e+00, Lambda2: -1.3e-01\n",
            "490 Loss treino: 6.08625188e-02, Loss edp: 4.40940494e-03, Lambda1: 5.4e+00, Lambda2: -1.3e-01\n",
            "500 Loss treino: 6.01546429e-02, Loss edp: 4.41217283e-03, Lambda1: 5.5e+00, Lambda2: -1.4e-01\n",
            "510 Loss treino: 5.94434477e-02, Loss edp: 4.34873393e-03, Lambda1: 5.5e+00, Lambda2: -1.5e-01\n",
            "520 Loss treino: 6.46298528e-02, Loss edp: 1.09442789e-02, Lambda1: 5.5e+00, Lambda2: -1.5e-01\n",
            "530 Loss treino: 5.88807575e-02, Loss edp: 4.14141919e-03, Lambda1: 5.5e+00, Lambda2: -1.6e-01\n",
            "540 Loss treino: 5.85693941e-02, Loss edp: 5.00351144e-03, Lambda1: 5.5e+00, Lambda2: -1.7e-01\n",
            "550 Loss treino: 5.73217645e-02, Loss edp: 4.00289753e-03, Lambda1: 5.5e+00, Lambda2: -1.7e-01\n",
            "560 Loss treino: 5.66087067e-02, Loss edp: 3.75933689e-03, Lambda1: 5.5e+00, Lambda2: -1.8e-01\n",
            "570 Loss treino: 5.60832918e-02, Loss edp: 3.74945300e-03, Lambda1: 5.5e+00, Lambda2: -1.9e-01\n",
            "580 Loss treino: 5.55397943e-02, Loss edp: 3.62896500e-03, Lambda1: 5.5e+00, Lambda2: -1.9e-01\n",
            "590 Loss treino: 5.50164357e-02, Loss edp: 3.52897192e-03, Lambda1: 5.5e+00, Lambda2: -2.0e-01\n",
            "600 Loss treino: 5.45061007e-02, Loss edp: 3.44739924e-03, Lambda1: 5.5e+00, Lambda2: -2.1e-01\n",
            "610 Loss treino: 5.40041775e-02, Loss edp: 3.34688253e-03, Lambda1: 5.5e+00, Lambda2: -2.2e-01\n",
            "620 Loss treino: 5.35113215e-02, Loss edp: 3.27070919e-03, Lambda1: 5.6e+00, Lambda2: -2.2e-01\n",
            "630 Loss treino: 5.33815250e-02, Loss edp: 3.78701859e-03, Lambda1: 5.6e+00, Lambda2: -2.3e-01\n",
            "640 Loss treino: 5.56418151e-02, Loss edp: 5.18857595e-03, Lambda1: 5.6e+00, Lambda2: -2.4e-01\n",
            "650 Loss treino: 5.24270125e-02, Loss edp: 3.00098374e-03, Lambda1: 5.6e+00, Lambda2: -2.4e-01\n",
            "660 Loss treino: 5.21745421e-02, Loss edp: 3.43882176e-03, Lambda1: 5.6e+00, Lambda2: -2.5e-01\n",
            "670 Loss treino: 5.16579635e-02, Loss edp: 3.20752873e-03, Lambda1: 5.6e+00, Lambda2: -2.5e-01\n",
            "680 Loss treino: 5.11854254e-02, Loss edp: 2.98132538e-03, Lambda1: 5.6e+00, Lambda2: -2.6e-01\n",
            "690 Loss treino: 5.07795736e-02, Loss edp: 2.84248870e-03, Lambda1: 5.6e+00, Lambda2: -2.7e-01\n",
            "700 Loss treino: 5.04280701e-02, Loss edp: 2.70686462e-03, Lambda1: 5.6e+00, Lambda2: -2.7e-01\n",
            "710 Loss treino: 5.00782840e-02, Loss edp: 2.71133077e-03, Lambda1: 5.6e+00, Lambda2: -2.8e-01\n",
            "720 Loss treino: 4.97410074e-02, Loss edp: 2.61880667e-03, Lambda1: 5.6e+00, Lambda2: -2.8e-01\n",
            "730 Loss treino: 4.95640039e-02, Loss edp: 2.61171465e-03, Lambda1: 5.6e+00, Lambda2: -2.9e-01\n",
            "740 Loss treino: 4.97646630e-02, Loss edp: 2.94900406e-03, Lambda1: 5.6e+00, Lambda2: -2.9e-01\n",
            "750 Loss treino: 4.89254594e-02, Loss edp: 2.49588629e-03, Lambda1: 5.6e+00, Lambda2: -3.0e-01\n",
            "760 Loss treino: 4.85583991e-02, Loss edp: 2.48303940e-03, Lambda1: 5.6e+00, Lambda2: -3.0e-01\n",
            "770 Loss treino: 4.83107269e-02, Loss edp: 2.47678859e-03, Lambda1: 5.6e+00, Lambda2: -3.1e-01\n",
            "780 Loss treino: 4.79994416e-02, Loss edp: 2.45521404e-03, Lambda1: 5.7e+00, Lambda2: -3.1e-01\n",
            "790 Loss treino: 4.76869866e-02, Loss edp: 2.55938806e-03, Lambda1: 5.7e+00, Lambda2: -3.2e-01\n",
            "800 Loss treino: 5.13193011e-02, Loss edp: 6.06193487e-03, Lambda1: 5.7e+00, Lambda2: -3.2e-01\n",
            "810 Loss treino: 4.75608297e-02, Loss edp: 3.12672392e-03, Lambda1: 5.7e+00, Lambda2: -3.3e-01\n",
            "820 Loss treino: 4.70560230e-02, Loss edp: 2.66805734e-03, Lambda1: 5.7e+00, Lambda2: -3.4e-01\n",
            "830 Loss treino: 4.66518477e-02, Loss edp: 2.68440670e-03, Lambda1: 5.7e+00, Lambda2: -3.4e-01\n",
            "840 Loss treino: 4.62372527e-02, Loss edp: 2.48350296e-03, Lambda1: 5.7e+00, Lambda2: -3.5e-01\n",
            "850 Loss treino: 4.88255359e-02, Loss edp: 4.82991477e-03, Lambda1: 5.7e+00, Lambda2: -3.5e-01\n",
            "860 Loss treino: 4.57833931e-02, Loss edp: 2.81849969e-03, Lambda1: 5.7e+00, Lambda2: -3.6e-01\n",
            "870 Loss treino: 4.58018705e-02, Loss edp: 3.18962010e-03, Lambda1: 5.7e+00, Lambda2: -3.6e-01\n",
            "880 Loss treino: 4.49506119e-02, Loss edp: 2.53305212e-03, Lambda1: 5.7e+00, Lambda2: -3.7e-01\n",
            "890 Loss treino: 4.46774773e-02, Loss edp: 2.46650516e-03, Lambda1: 5.7e+00, Lambda2: -3.7e-01\n",
            "900 Loss treino: 4.42310907e-02, Loss edp: 2.51306803e-03, Lambda1: 5.7e+00, Lambda2: -3.8e-01\n",
            "910 Loss treino: 4.42018174e-02, Loss edp: 3.00933514e-03, Lambda1: 5.7e+00, Lambda2: -3.8e-01\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cf4f5abadfa3>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0merro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#Salvando os erros para listar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    870\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}